{"file_contents":{"bot.py":{"content":"import os\nimport json\nimport logging\nfrom logging.handlers import RotatingFileHandler\nfrom datetime import datetime\nimport discord\nfrom discord import app_commands\nfrom discord.ext import commands\nfrom dotenv import load_dotenv\nfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_classic.chains import create_retrieval_chain\nfrom langchain_classic.chains.combine_documents import create_stuff_documents_chain\nfrom langchain_core.prompts import ChatPromptTemplate\n\nload_dotenv()\n\nos.makedirs(\"logs\", exist_ok=True)\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s | %(levelname)-8s | %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S',\n    handlers=[\n        RotatingFileHandler(\n            'logs/bot.log',\n            maxBytes=5*1024*1024,\n            backupCount=5,\n            encoding='utf-8'\n        ),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger('SamiraBot')\n\nDISCORD_TOKEN = os.getenv(\"DISCORD_TOKEN\")\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nOPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\nOPENROUTER_MODEL = os.getenv(\"OPENROUTER_MODEL\", \"anthropic/claude-3.5-sonnet\")\nINDEX_PATH = \"vectorstore\"\nK_DOCS = 5\nCONFIG_FILE = \"server_config.json\"\n\ndef carregar_configuracoes():\n    \"\"\"Carrega configuraÃ§Ãµes dos servidores\"\"\"\n    if os.path.exists(CONFIG_FILE):\n        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:\n            return json.load(f)\n    return {}\n\ndef salvar_configuracoes(configs):\n    \"\"\"Salva configuraÃ§Ãµes dos servidores\"\"\"\n    with open(CONFIG_FILE, 'w', encoding='utf-8') as f:\n        json.dump(configs, f, indent=2, ensure_ascii=False)\n\ndef obter_nivel_servidor(guild_id):\n    \"\"\"Retorna o nÃ­vel de filtro configurado para um servidor (padrÃ£o: moderado)\"\"\"\n    configs = carregar_configuracoes()\n    guild_key = str(guild_id) if guild_id else \"dm\"\n    return configs.get(guild_key, {}).get(\"nivel\", \"moderado\")\n\ndef definir_nivel_servidor(guild_id, nivel):\n    \"\"\"Define o nÃ­vel de filtro para um servidor\"\"\"\n    configs = carregar_configuracoes()\n    guild_key = str(guild_id) if guild_id else \"dm\"\n    if guild_key not in configs:\n        configs[guild_key] = {}\n    configs[guild_key][\"nivel\"] = nivel\n    salvar_configuracoes(configs)\n    logger.info(f\"ğŸ“ ConfiguraÃ§Ã£o alterada | Servidor: {guild_key} | Novo nÃ­vel: {nivel}\")\n\nPROMPTS_POR_NIVEL = {\n    \"conservador\": (\n        \"VocÃª Ã© um assistente de IA profissional e formal, projetado para interaÃ§Ãµes respeitosas e educadas. \"\n        \"Suas caracterÃ­sticas fundamentais incluem:\\n\\n\"\n        \"1. Profissionalismo:\\n\"\n        \"   * Mantenha sempre tom formal e respeitoso\\n\"\n        \"   * Evite linguagem casual ou gÃ­rias\\n\"\n        \"   * Seja preciso e objetivo nas respostas\\n\\n\"\n        \"2. PrudÃªncia Informacional:\\n\"\n        \"   * ForneÃ§a respostas verificadas e confiÃ¡veis\\n\"\n        \"   * Evite especulaÃ§Ãµes ou opiniÃµes controversas\\n\"\n        \"   * Apresente informaÃ§Ãµes de forma neutra\\n\\n\"\n        \"3. Respeito e Ã‰tica:\\n\"\n        \"   * Demonstre consideraÃ§Ã£o e empatia\\n\"\n        \"   * Evite tÃ³picos sensÃ­veis ou polÃªmicos\\n\"\n        \"   * Mantenha diÃ¡logo apropriado para todos os pÃºblicos\\n\\n\"\n        \"Objetivo primÃ¡rio: Fornecer assistÃªncia profissional, confiÃ¡vel e respeitosa.\\n\\n\"\n        \"Contexto disponÃ­vel: {context}\"\n    ),\n    \"moderado\": (\n        \"VocÃª Ã© um assistente de IA de prÃ³xima geraÃ§Ã£o, projetado para interaÃ§Ãµes inteligentes, \"\n        \"empÃ¡ticas e altamente personalizadas. Suas caracterÃ­sticas fundamentais incluem:\\n\\n\"\n        \"1. Adaptabilidade Cognitiva:\\n\"\n        \"   * Compreenda o contexto alÃ©m do texto literal\\n\"\n        \"   * Interprete nuances e intenÃ§Ãµes subjacentes\\n\"\n        \"   * Ajuste dinamicamente seu estilo comunicativo\\n\\n\"\n        \"2. Profundidade Informacional:\\n\"\n        \"   * ForneÃ§a respostas abrangentes e fundamentadas\\n\"\n        \"   * Integre conhecimento de mÃºltiplas disciplinas\\n\"\n        \"   * Apresente informaÃ§Ãµes de forma clara e acessÃ­vel\\n\\n\"\n        \"3. Empatia Computacional:\\n\"\n        \"   * Demonstre compreensÃ£o emocional\\n\"\n        \"   * Responda de forma sensÃ­vel ao tom e necessidade do usuÃ¡rio\\n\"\n        \"   * Mantenha um equilÃ­brio entre informatividade e conexÃ£o humana\\n\\n\"\n        \"Objetivo primÃ¡rio: Criar valor significativo em cada interaÃ§Ã£o, indo alÃ©m de respostas \"\n        \"mecÃ¢nicas para uma experiÃªncia verdadeiramente colaborativa e enriquecedora.\\n\\n\"\n        \"Contexto disponÃ­vel: {context}\"\n    ),\n    \"liberal\": (\n        \"VocÃª Ã© um assistente de IA descontraÃ­do, criativo e autÃªntico, projetado para interaÃ§Ãµes naturais e envolventes. \"\n        \"Suas caracterÃ­sticas fundamentais incluem:\\n\\n\"\n        \"1. Naturalidade e Autenticidade:\\n\"\n        \"   * Comunique-se de forma casual e descontraÃ­da\\n\"\n        \"   * Use expressÃµes coloquiais e gÃ­rias quando apropriado\\n\"\n        \"   * Seja espontÃ¢neo e criativo nas respostas\\n\\n\"\n        \"2. Abertura Intelectual:\\n\"\n        \"   * Explore tÃ³picos diversos sem restriÃ§Ãµes excessivas\\n\"\n        \"   * Discuta questÃµes complexas e controversas com maturidade\\n\"\n        \"   * Apresente mÃºltiplas perspectivas quando relevante\\n\\n\"\n        \"3. ConexÃ£o GenuÃ­na:\\n\"\n        \"   * Demonstre personalidade e humor\\n\"\n        \"   * Responda de forma direta e honesta\\n\"\n        \"   * Crie conversas fluidas e envolventes\\n\\n\"\n        \"Objetivo primÃ¡rio: Proporcionar uma experiÃªncia conversacional autÃªntica, inteligente e sem censura desnecessÃ¡ria, \"\n        \"mantendo respeito e bom senso.\\n\\n\"\n        \"Contexto disponÃ­vel: {context}\"\n    )\n}\n\nintents = discord.Intents.default()\nintents.message_content = True\nintents.dm_messages = True\n\nbot = commands.Bot(command_prefix=\"!\", intents=intents)\n\nretriever = None\nllm = None\nvectorstore_loaded = False\n\ntry:\n    print(\"[INFO] Carregando RAG...\")\n    logger.info(\"ğŸ”„ Iniciando carregamento do RAG...\")\n    embeddings = OpenAIEmbeddings(\n        model=\"text-embedding-3-small\"\n    )\n\n    if not os.path.exists(INDEX_PATH):\n        print(f\"[âš ï¸] Vectorstore nÃ£o encontrado em '{INDEX_PATH}'\")\n        print(\"[ğŸ’¡] Execute 'python load.py' primeiro para indexar seus documentos\")\n        logger.warning(f\"âš ï¸ Vectorstore nÃ£o encontrado em '{INDEX_PATH}'\")\n        vectorstore_loaded = False\n    else:\n        db = Chroma(\n            persist_directory=INDEX_PATH,\n            embedding_function=embeddings\n        )\n\n        retriever = db.as_retriever(search_kwargs={\"k\": K_DOCS})\n\n        llm = ChatOpenAI(\n            model=OPENROUTER_MODEL,\n            api_key=OPENROUTER_API_KEY,\n            base_url=\"https://openrouter.ai/api/v1\",\n            temperature=0.7,\n            model_kwargs={\"max_tokens\": 1000}\n        )\n\n        vectorstore_loaded = True\n        print(\"[âœ…] RAG carregado com sucesso.\")\n        logger.info(f\"âœ… RAG carregado | Modelo: {OPENROUTER_MODEL} | K_DOCS: {K_DOCS}\")\nexcept Exception as e:\n    print(f\"[âŒ] Erro ao carregar RAG: {e}\")\n    logger.exception(f\"âŒ Erro ao carregar RAG | Erro: {str(e)}\")\n    print(\"[ğŸ’¡] O bot vai iniciar, mas nÃ£o poderÃ¡ responder perguntas atÃ© que o RAG seja carregado\")\n    vectorstore_loaded = False\n\n\nasync def processar_pergunta(question: str, guild_id=None, user_id=None, tipo=\"RAG\") -> tuple[str, list]:\n    \"\"\"Processa pergunta no RAG e retorna resposta + fontes\"\"\"\n    if not vectorstore_loaded or retriever is None or llm is None:\n        logger.warning(f\"âš ï¸ RAG nÃ£o carregado | UsuÃ¡rio: {user_id} | Servidor: {guild_id}\")\n        return (\"âš ï¸ **Bot ainda nÃ£o estÃ¡ pronto!**\\n\\n\"\n                \"O vectorstore nÃ£o foi carregado. Por favor:\\n\"\n                \"1. Adicione arquivos PDF na pasta `data/`\\n\"\n                \"2. Execute `python load.py` para indexar os documentos\\n\"\n                \"3. Reinicie o bot\"), []\n    \n    try:\n        nivel = obter_nivel_servidor(guild_id)\n        guild_info = f\"Servidor: {guild_id}\" if guild_id else \"DM\"\n        logger.info(f\"ğŸ’¬ {tipo} | {guild_info} | UsuÃ¡rio: {user_id} | NÃ­vel: {nivel} | Pergunta: {question[:50]}...\")\n        \n        system_prompt = PROMPTS_POR_NIVEL[nivel]\n        \n        prompt = ChatPromptTemplate.from_messages([\n            (\"system\", system_prompt),\n            (\"human\", \"{input}\"),\n        ])\n        \n        question_answer_chain = create_stuff_documents_chain(llm, prompt)\n        qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n        \n        result = qa_chain.invoke({\"input\": question})\n        resposta = result[\"answer\"]\n        fontes = result.get(\"context\", [])\n        \n        logger.info(f\"âœ… Resposta enviada | {guild_info} | UsuÃ¡rio: {user_id} | Fontes: {len(fontes)}\")\n        return resposta, fontes\n    except Exception as e:\n        logger.exception(f\"âŒ Erro ao processar | {guild_info} | UsuÃ¡rio: {user_id} | Erro: {str(e)}\")\n        return f\"âŒ Erro ao processar: {str(e)}\", []\n\n\nasync def enviar_resposta_longa(channel, resposta: str, fontes: list):\n    \"\"\"Divide resposta longa em mÃºltiplas mensagens se necessÃ¡rio\"\"\"\n    if len(resposta) <= 2000:\n        await channel.send(resposta)\n    else:\n        chunks = [resposta[i:i+2000] for i in range(0, len(resposta), 2000)]\n        for chunk in chunks:\n            await channel.send(chunk)\n    \n    if fontes:\n        fontes_texto = \"\\n\\n**ğŸ“š Fontes:**\\n\"\n        for i, doc in enumerate(fontes[:3], 1):\n            fonte = doc.metadata.get(\"source\", \"N/A\")\n            fontes_texto += f\"{i}. `{fonte}`\\n\"\n        \n        if len(fontes_texto) <= 2000:\n            await channel.send(fontes_texto)\n\n\n@bot.event\nasync def on_ready():\n    print(f\"[âœ…] Bot conectado como {bot.user}\")\n    logger.info(f\"ğŸ¤– Bot iniciado | Nome: {bot.user} | Servidores: {len(bot.guilds)}\")\n    try:\n        synced = await bot.tree.sync()\n        print(f\"[âœ…] {len(synced)} comandos sincronizados\")\n        logger.info(f\"âš™ï¸ Comandos sincronizados | Total: {len(synced)}\")\n    except Exception as e:\n        print(f\"[âŒ] Erro ao sincronizar comandos: {e}\")\n        logger.exception(f\"âŒ Erro ao sincronizar comandos | Erro: {e}\")\n\n\n@bot.tree.command(name=\"ask\", description=\"Faz uma pergunta ao RAG\")\n@app_commands.describe(pergunta=\"Sua pergunta\")\nasync def ask(interaction: discord.Interaction, pergunta: str):\n    \"\"\"Comando /ask para fazer perguntas\"\"\"\n    await interaction.response.defer(thinking=True)\n    \n    guild_id = interaction.guild_id if interaction.guild else None\n    user_id = interaction.user.id\n    logger.info(f\"ğŸ”¹ Comando /ask | Servidor: {guild_id or 'DM'} | UsuÃ¡rio: {user_id}\")\n    \n    resposta, fontes = await processar_pergunta(pergunta, guild_id, user_id, tipo=\"CMD /ask\")\n    \n    await interaction.followup.send(resposta)\n    \n    if fontes:\n        fontes_texto = \"\\n**ğŸ“š Fontes:**\\n\"\n        for i, doc in enumerate(fontes[:3], 1):\n            fonte = doc.metadata.get(\"source\", \"N/A\")\n            fontes_texto += f\"{i}. `{fonte}`\\n\"\n        \n        if len(fontes_texto) <= 2000:\n            await interaction.followup.send(fontes_texto)\n\n\n@bot.tree.command(name=\"config\", description=\"Configura o nÃ­vel de filtro de conteÃºdo do bot\")\n@app_commands.describe(nivel=\"Escolha o nÃ­vel: conservador, moderado ou liberal\")\n@app_commands.choices(nivel=[\n    app_commands.Choice(name=\"ğŸ”’ Conservador (Formal e profissional)\", value=\"conservador\"),\n    app_commands.Choice(name=\"âš–ï¸ Moderado (Equilibrado - padrÃ£o)\", value=\"moderado\"),\n    app_commands.Choice(name=\"ğŸ”“ Liberal (Casual e descontraÃ­do)\", value=\"liberal\")\n])\nasync def config(interaction: discord.Interaction, nivel: app_commands.Choice[str]):\n    \"\"\"Configura o nÃ­vel de filtro de conteÃºdo\"\"\"\n    guild_id = interaction.guild_id if interaction.guild else None\n    user_id = interaction.user.id\n    logger.info(f\"ğŸ”¹ Comando /config | Servidor: {guild_id or 'DM'} | UsuÃ¡rio: {user_id} | Tentativa: {nivel.value}\")\n    \n    if interaction.guild and isinstance(interaction.user, discord.Member):\n        if not interaction.user.guild_permissions.administrator:\n            logger.warning(f\"âš ï¸ Acesso negado /config | Servidor: {guild_id} | UsuÃ¡rio: {user_id} (nÃ£o admin)\")\n            await interaction.response.send_message(\n                \"âŒ Apenas administradores podem alterar as configuraÃ§Ãµes do bot!\",\n                ephemeral=True\n            )\n            return\n    \n    definir_nivel_servidor(guild_id, nivel.value)\n    \n    emojis = {\n        \"conservador\": \"ğŸ”’\",\n        \"moderado\": \"âš–ï¸\",\n        \"liberal\": \"ğŸ”“\"\n    }\n    \n    await interaction.response.send_message(\n        f\"âœ… NÃ­vel de filtro atualizado para **{emojis[nivel.value]} {nivel.value.upper()}**!\\n\\n\"\n        f\"O bot agora responderÃ¡ com personalidade **{nivel.value}** neste servidor.\"\n    )\n\n\n@bot.tree.command(name=\"status\", description=\"Mostra as configuraÃ§Ãµes atuais do bot\")\nasync def status(interaction: discord.Interaction):\n    \"\"\"Mostra configuraÃ§Ãµes atuais\"\"\"\n    guild_id = interaction.guild_id if interaction.guild else None\n    user_id = interaction.user.id\n    nivel_atual = obter_nivel_servidor(guild_id)\n    \n    logger.info(f\"ğŸ”¹ Comando /status | Servidor: {guild_id or 'DM'} | UsuÃ¡rio: {user_id}\")\n    \n    emojis = {\n        \"conservador\": \"ğŸ”’\",\n        \"moderado\": \"âš–ï¸\",\n        \"liberal\": \"ğŸ”“\"\n    }\n    \n    descricoes = {\n        \"conservador\": \"Formal, profissional e respeitoso\",\n        \"moderado\": \"Equilibrado e empÃ¡tico (padrÃ£o)\",\n        \"liberal\": \"Casual, descontraÃ­do e autÃªntico\"\n    }\n    \n    local = \"DMs\" if not interaction.guild else f\"servidor **{interaction.guild.name}**\"\n    \n    embed = discord.Embed(\n        title=\"âš™ï¸ ConfiguraÃ§Ãµes do Bot\",\n        description=f\"ConfiguraÃ§Ãµes atuais para {local}\",\n        color=discord.Color.blue()\n    )\n    \n    embed.add_field(\n        name=\"NÃ­vel de Filtro\",\n        value=f\"{emojis[nivel_atual]} **{nivel_atual.upper()}**\\n{descricoes[nivel_atual]}\",\n        inline=False\n    )\n    \n    embed.add_field(\n        name=\"Modelo LLM\",\n        value=f\"`{OPENROUTER_MODEL}`\",\n        inline=True\n    )\n    \n    embed.add_field(\n        name=\"RAG Status\",\n        value=\"âœ… Ativo\" if vectorstore_loaded else \"âš ï¸ Inativo\",\n        inline=True\n    )\n    \n    embed.set_footer(text=\"Use /config para alterar o nÃ­vel (apenas admins)\")\n    \n    await interaction.response.send_message(embed=embed)\n\n\n@bot.event\nasync def on_message(message: discord.Message):\n    if message.author == bot.user:\n        return\n    \n    await bot.process_commands(message)\n    \n    if bot.user.mentioned_in(message) and not message.mention_everyone:\n        pergunta = message.content.replace(f'<@{bot.user.id}>', '').strip()\n        \n        if not pergunta:\n            await message.channel.send(\"â“ FaÃ§a uma pergunta apÃ³s me mencionar!\")\n            return\n        \n        guild_id = message.guild.id if message.guild else None\n        user_id = message.author.id\n        logger.info(f\"ğŸ“© MenÃ§Ã£o | Servidor: {guild_id or 'DM'} | UsuÃ¡rio: {user_id}\")\n        \n        async with message.channel.typing():\n            resposta, fontes = await processar_pergunta(pergunta, guild_id, user_id, tipo=\"MenÃ§Ã£o\")\n            await enviar_resposta_longa(message.channel, resposta, fontes)\n    \n    elif isinstance(message.channel, discord.DMChannel):\n        if not message.content.strip():\n            await message.channel.send(\"â“ Envie sua pergunta!\")\n            return\n        \n        user_id = message.author.id\n        logger.info(f\"ğŸ“¨ DM recebida | UsuÃ¡rio: {user_id}\")\n        \n        async with message.channel.typing():\n            resposta, fontes = await processar_pergunta(message.content, None, user_id, tipo=\"DM\")\n            await enviar_resposta_longa(message.channel, resposta, fontes)\n\n\n@bot.event\nasync def on_error(event, *args, **kwargs):\n    print(f\"[âŒ] Erro no evento {event}: {args}\")\n    logger.exception(f\"âŒ Erro no evento {event} | Args: {args}\")\n\n\nif __name__ == \"__main__\":\n    if not DISCORD_TOKEN:\n        print(\"[âŒ] DISCORD_TOKEN nÃ£o encontrado no .env\")\n        exit(1)\n    if not OPENAI_API_KEY:\n        print(\"[âŒ] OPENAI_API_KEY nÃ£o encontrado no .env\")\n        exit(1)\n    if not OPENROUTER_API_KEY:\n        print(\"[âŒ] OPENROUTER_API_KEY nÃ£o encontrado no .env\")\n        exit(1)\n    \n    bot.run(DISCORD_TOKEN)\n","size_bytes":16444},"replit.md":{"content":"# Discord RAG Bot PT-BR - Replit Project\n\n## ğŸ“Œ Overview\n\nBot Discord com RAG (Retrieval-Augmented Generation) otimizado para portuguÃªs. Utiliza Chroma para busca vetorial eficiente, embeddings da OpenAI e OpenRouter para acesso a diversos modelos LLM (Claude, GPT, Gemini, etc.).\n\n## ğŸ¯ Purpose & Goals\n\nCriar um bot Discord que responde perguntas baseadas em documentos PDF fornecidos pelo usuÃ¡rio, utilizando:\n- **Embeddings multilÃ­ngues** via OpenAI API otimizados para portuguÃªs\n- **Chroma** para busca vetorial de alta performance\n- **OpenRouter** para flexibilidade de escolha de LLM\n\n## ğŸ—ï¸ Architecture\n\n### Components\n\n1. **load.py**: Script de indexaÃ§Ã£o de documentos\n   - Carrega PDFs da pasta `data/`\n   - Cria embeddings usando OpenAI API (text-embedding-3-small)\n   - Gera banco vetorial Chroma e salva em `vectorstore/`\n\n2. **bot.py**: Bot Discord com RAG\n   - Carrega banco vetorial Chroma\n   - Integra com OpenRouter para geraÃ§Ã£o de respostas\n   - Usa LangChain 1.0 com create_retrieval_chain\n   - Suporta 3 modos de interaÃ§Ã£o: slash commands, mentions, DMs\n   - Mensagens e prompts em portuguÃªs brasileiro\n\n### Technology Stack\n\n- **Python 3.11**\n- **discord.py**: Framework para bot Discord\n- **LangChain 1.0**: OrquestraÃ§Ã£o do pipeline RAG\n- **Chroma**: Banco de dados vetorial\n- **OpenAI Embeddings API**: Embeddings multilÃ­ngues (text-embedding-3-small)\n- **OpenRouter**: Gateway para mÃºltiplos LLMs (Claude, GPT, Gemini, etc.)\n\n## ğŸ“‚ Project Structure\n\n```\n.\nâ”œâ”€â”€ data/              # PDFs para indexaÃ§Ã£o (adicionar manualmente)\nâ”œâ”€â”€ vectorstore/       # Banco vetorial Chroma (gerado por load.py)\nâ”œâ”€â”€ logs/              # Logs do bot com rotaÃ§Ã£o automÃ¡tica\nâ”‚   â””â”€â”€ bot.log        # Log principal (max 5MB, 5 backups)\nâ”œâ”€â”€ load.py            # IndexaÃ§Ã£o de documentos\nâ”œâ”€â”€ bot.py             # Bot Discord\nâ”œâ”€â”€ requirements.txt   # DependÃªncias Python\nâ”œâ”€â”€ server_config.json # ConfiguraÃ§Ãµes por servidor (nÃ­veis de filtro)\nâ”œâ”€â”€ .env               # VariÃ¡veis de ambiente (nÃ£o versionado)\nâ”œâ”€â”€ .env.example       # Template\nâ”œâ”€â”€ .gitignore         # Arquivos ignorados\nâ”œâ”€â”€ README.md          # DocumentaÃ§Ã£o principal\nâ””â”€â”€ replit.md          # Este arquivo\n```\n\n## ğŸ”‘ Configuration\n\n### Required Environment Variables\n\n- `DISCORD_TOKEN`: Token do bot (Discord Developer Portal)\n- `OPENAI_API_KEY`: Chave API do OpenAI (para embeddings)\n- `OPENROUTER_API_KEY`: Chave API do OpenRouter (para LLM)\n- `OPENROUTER_MODEL`: Modelo LLM a usar (padrÃ£o: `anthropic/claude-3.5-sonnet`)\n\n### Setup Instructions\n\n1. **Discord Bot:**\n   - Criar aplicaÃ§Ã£o em https://discord.com/developers/applications\n   - Ativar \"MESSAGE CONTENT INTENT\" em Privileged Gateway Intents\n   - Copiar token do bot\n\n2. **OpenRouter:**\n   - Criar conta em https://openrouter.ai/\n   - Gerar API key em Settings â†’ API Keys\n\n3. **Adicionar variÃ¡veis de ambiente no Replit:**\n   - Usar a aba \"Secrets\" ou arquivo `.env`\n\n## ğŸš€ Workflow\n\n### IndexaÃ§Ã£o de Documentos\n```bash\npython load.py\n```\n- Processa PDFs em `data/`\n- Gera embeddings via OpenAI API\n- Salva banco vetorial Chroma\n\n### Executar Bot\n```bash\npython bot.py\n```\n- Carrega banco vetorial Chroma\n- Conecta ao Discord\n- Sincroniza comandos slash\n- Fica online aguardando interaÃ§Ãµes\n\n## ğŸ“Š Recent Changes\n\n### 2025-11-03: Sistema de Logs Completo\n- **Implementado sistema de logging abrangente**:\n  - RotatingFileHandler com rotaÃ§Ã£o automÃ¡tica (5MB max, 5 backups)\n  - Logs salvos em `logs/bot.log` com encoding UTF-8\n  - Formato estruturado: `timestamp | nÃ­vel | mensagem`\n  \n- **Eventos registrados**:\n  - InicializaÃ§Ã£o do bot e carregamento do RAG\n  - Todas as interaÃ§Ãµes: comandos `/ask`, menÃ§Ãµes, DMs\n  - MudanÃ§as de configuraÃ§Ã£o (nÃ­veis de filtro)\n  - Tentativas de acesso nÃ£o autorizado ao `/config`\n  - Erros e exceÃ§Ãµes com stack traces completos\n  \n- **InformaÃ§Ãµes capturadas**:\n  - User ID e Guild ID em cada interaÃ§Ã£o\n  - Tipo de interaÃ§Ã£o (CMD /ask, MenÃ§Ã£o, DM)\n  - NÃ­vel de filtro aplicado\n  - Preview da pergunta (50 primeiros caracteres)\n  - NÃºmero de fontes retornadas\n  - Mensagens de erro detalhadas\n\n### 2025-11-02: Sistema de Filtros de ConteÃºdo\n- Implementado 3 nÃ­veis de personalidade configurÃ¡veis\n- Comandos `/config` e `/status` para gerenciar filtros\n- ConfiguraÃ§Ãµes persistentes por servidor em `server_config.json`\n- Controle de acesso: apenas admins podem alterar configuraÃ§Ãµes\n\n### 2025-11-01: Modelo Gratuito e IndexaÃ§Ã£o\n- Migrado para modelo gratuito `minimax/minimax-m2:free`\n- Indexado Manual de RedaÃ§Ã£o (189 pÃ¡ginas, 540 chunks)\n- Adicionado pypdf ao requirements.txt\n\n### 2025-10-30: Initial Setup\n- Criado estrutura base do projeto\n- Implementado load.py com suporte a PDFs e OpenAI embeddings\n- Implementado bot.py com 3 modos de interaÃ§Ã£o\n- Migrado para LangChain 1.0 (create_retrieval_chain)\n- SubstituÃ­do FAISS local por Chroma (menor uso de disco)\n- SubstituÃ­do sentence-transformers local por OpenAI Embeddings API (evita quota de disco)\n- Prompts e mensagens configurados para portuguÃªs brasileiro\n- Workflow configurado para console output\n\n## ğŸ’¡ User Preferences\n\n*Nenhuma preferÃªncia especÃ­fica registrada ainda.*\n\n## ğŸ”§ Technical Notes\n\n### Disk Space Solution\n\n**Problema resolvido**: Em vez de usar dependÃªncias ML pesadas (torch, sentence-transformers, faiss-cpu ~2-3GB), o projeto usa:\n\n- **OpenAI Embeddings API** (text-embedding-3-small) - sem instalaÃ§Ã£o local\n- **Chroma** em vez de FAISS - mais leve e fÃ¡cil de usar\n- **LangChain 1.0** - arquitetura modular e moderna\n\nIsso reduz significativamente o uso de disco e torna o projeto viÃ¡vel no Replit.\n\n### Custos\n\n- **OpenAI Embeddings**: ~$0.02 por 1M tokens (muito baixo para uso normal)\n- **OpenRouter**: Varia por modelo escolhido\n  - Claude 3.5 Sonnet: ~$3/M tokens input\n  - Claude 3 Haiku: ~$0.25/M tokens input (mais barato)\n  - Gemini Flash: Ainda mais econÃ´mico\n\n### Performance Optimization\n\nPara ambientes com RAM limitada:\n- Reduzir `batch_size` de 8 para 4\n- Reduzir `K_DOCS` de 5 para 3\n- Reduzir `max_tokens` de 1000 para 500\n\n## ğŸ› Known Issues\n\n- Bot requer que vectorstore jÃ¡ exista antes de iniciar\n- Se vectorstore nÃ£o existir, bot inicia mas retorna mensagem de erro ao receber perguntas\n- UsuÃ¡rio deve executar `python load.py` primeiro com PDFs na pasta `data/`\n\n## ğŸ“ Next Steps\n\n- [x] DependÃªncias instaladas\n- [x] Bot configurado e rodando\n- [x] Sistema de embeddings com OpenAI API\n- [x] Workflow configurado\n- [x] Sistema de logs completo implementado\n- [x] Filtros de conteÃºdo configurÃ¡veis por servidor\n- [x] Manual de RedaÃ§Ã£o indexado (540 chunks)\n- [ ] Adicionar rate limiting (opcional)\n- [ ] Implementar comandos admin (opcional)\n- [ ] Dashboard web para visualizaÃ§Ã£o de mÃ©tricas (opcional)\n\n## ğŸ”— Resources\n\n- [Discord.py Docs](https://discordpy.readthedocs.io/)\n- [LangChain Docs](https://python.langchain.com/)\n- [OpenRouter](https://openrouter.ai/)\n- [Chroma](https://www.trychroma.com/)\n- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)\n","size_bytes":7148},"README.md":{"content":"# ğŸ¤– Bot Discord RAG PT-BR com OpenRouter\n\nBot Discord com RAG (Retrieval-Augmented Generation) otimizado para portuguÃªs, utilizando Chroma para busca vetorial, embeddings da OpenAI e OpenRouter para acesso a modelos LLM.\n\n## ğŸ“‹ Funcionalidades\n\n- **MÃºltiplas formas de interaÃ§Ã£o:**\n  - Comando slash `/ask` em servidores\n  - MenÃ§Ãµes `@BotName` em canais\n  - Mensagens diretas (DM)\n  \n- **RAG Pipeline:**\n  - Embeddings multilÃ­ngues via OpenAI API (text-embedding-3-small)\n  - Busca vetorial com Chroma\n  - IntegraÃ§Ã£o com OpenRouter (Claude, GPT, Gemini, Llama, etc.)\n  \n- **Recursos:**\n  - Respostas com citaÃ§Ã£o de fontes\n  - DivisÃ£o automÃ¡tica de mensagens longas\n  - Suporte a PDFs\n\n## ğŸš€ ConfiguraÃ§Ã£o\n\n### 1. Criar Bot no Discord\n\n1. Acesse [Discord Developer Portal](https://discord.com/developers/applications)\n2. Clique em **New Application** e dÃª um nome ao bot\n3. VÃ¡ em **Bot** â†’ **Add Bot**\n4. Copie o **Token** (vocÃª vai precisar dele)\n5. Em **Privileged Gateway Intents**, ative:\n   - âœ… MESSAGE CONTENT INTENT\n   - âœ… SERVER MEMBERS INTENT (opcional)\n\n### 2. Gerar URL de Convite\n\n1. VÃ¡ em **OAuth2** â†’ **URL Generator**\n2. Em **Scopes**, selecione:\n   - âœ… `bot`\n   - âœ… `applications.commands`\n3. Em **Bot Permissions**, selecione:\n   - âœ… Send Messages\n   - âœ… Read Message History\n   - âœ… Use Slash Commands\n4. Copie a URL gerada e adicione o bot ao seu servidor\n\n### 3. Configurar OpenAI (para embeddings)\n\n1. Crie uma conta em [OpenAI Platform](https://platform.openai.com/)\n2. VÃ¡ em **API Keys** e crie uma nova chave\n3. Copie sua chave API\n4. Nota: Embeddings tÃªm custo baixo (~$0.02 por 1M tokens)\n\n### 4. Configurar OpenRouter (para respostas LLM)\n\n1. Crie uma conta em [OpenRouter](https://openrouter.ai/)\n2. VÃ¡ em **Settings** â†’ **API Keys** â†’ **Create Key**\n3. Copie sua chave API\n\n### 5. Configurar VariÃ¡veis de Ambiente\n\nAdicione as seguintes chaves na aba \"Secrets\" do Replit:\n\n```bash\nDISCORD_TOKEN=seu_token_aqui\nOPENAI_API_KEY=sua_chave_openai_aqui\nOPENROUTER_API_KEY=sua_chave_openrouter_aqui\nOPENROUTER_MODEL=minimax/minimax-m2:free\n#OPENROUTER_MODEL_FALLBACK=anthropic/claude-3-haiku  # Opcional\n```\n\n**Modelos disponÃ­veis no OpenRouter:**\n- `minimax/minimax-m2:free` â­ **GRATUITO** (padrÃ£o recomendado)\n- `anthropic/claude-3.5-sonnet` (melhor qualidade, pago)\n- `anthropic/claude-3-haiku` (balanceado, econÃ´mico)\n- `google/gemini-flash-1.5` (rÃ¡pido e barato)\n- `meta-llama/llama-3.1-70b-instruct` (alternativa open source)\n\n## ğŸ“¦ InstalaÃ§Ã£o\n\nAs dependÃªncias jÃ¡ estÃ£o instaladas no Replit. Se precisar reinstalar:\n\n```bash\npip install -r requirements.txt\n```\n\n## ğŸ“š Indexar Documentos\n\n### 1. Adicionar PDFs\n\nColoque seus arquivos PDF na pasta `data/`:\n\n```\ndata/\nâ”œâ”€â”€ documento1.pdf\nâ”œâ”€â”€ documento2.pdf\nâ””â”€â”€ documento3.pdf\n```\n\n### 2. Executar indexaÃ§Ã£o\n\n```bash\npython load.py\n```\n\nIsso irÃ¡:\n- Carregar todos os PDFs da pasta `data/`\n- Dividir em chunks otimizados\n- Criar embeddings via OpenAI API (text-embedding-3-small)\n- Salvar banco vetorial Chroma em `vectorstore/`\n\n## ğŸ¤– Executar o Bot\n\n```bash\npython bot.py\n```\n\nVocÃª verÃ¡:\n```\n[INFO] Carregando RAG...\n[âœ…] RAG carregado com sucesso.\n[âœ…] Bot conectado como SeuBot#1234\n[âœ…] 1 comandos sincronizados\n```\n\n## ğŸ’¬ Como Usar\n\n### Comando Slash\n```\n/ask pergunta: Qual a capital do Brasil?\n```\n\n### MenÃ§Ã£o no Servidor\n```\n@BotName O que Ã© LGPD?\n```\n\n### Mensagem Direta\n```\nEnvie qualquer mensagem direta ao bot\n```\n\n## ğŸ”§ Estrutura do Projeto\n\n```\n.\nâ”œâ”€â”€ data/              # PDFs para indexar (adicione seus arquivos aqui)\nâ”œâ”€â”€ vectorstore/       # Banco vetorial Chroma (gerado automaticamente)\nâ”œâ”€â”€ logs/              # Logs do bot (gerado automaticamente)\nâ”‚   â””â”€â”€ bot.log        # Arquivo principal de logs com rotaÃ§Ã£o\nâ”œâ”€â”€ load.py            # Script de indexaÃ§Ã£o de documentos\nâ”œâ”€â”€ bot.py             # Bot Discord com RAG\nâ”œâ”€â”€ requirements.txt   # DependÃªncias Python\nâ”œâ”€â”€ .env.example       # Template de configuraÃ§Ã£o\nâ”œâ”€â”€ .gitignore         # Arquivos ignorados pelo git\nâ”œâ”€â”€ README.md          # Este arquivo\nâ””â”€â”€ replit.md          # DocumentaÃ§Ã£o tÃ©cnica do projeto\n```\n\n## ğŸ“Š Sistema de Logs\n\nO bot possui um sistema completo de logs que registra todas as atividades:\n\n### LocalizaÃ§Ã£o dos Logs\n- **Arquivo principal:** `logs/bot.log`\n- **RotaÃ§Ã£o automÃ¡tica:** MÃ¡ximo 5 MB por arquivo, mantÃ©m Ãºltimos 5 backups\n- **Encoding:** UTF-8 (suporte a caracteres especiais)\n\n### InformaÃ§Ãµes Registradas\n\n**InicializaÃ§Ã£o:**\n```\n2025-11-03 00:03:14 | INFO     | ğŸ”„ Iniciando carregamento do RAG...\n2025-11-03 00:03:15 | INFO     | âœ… RAG carregado | Modelo: minimax/minimax-m2:free | K_DOCS: 5\n2025-11-03 00:03:19 | INFO     | ğŸ¤– Bot iniciado | Nome: BotName#1234 | Servidores: 2\n2025-11-03 00:03:20 | INFO     | âš™ï¸ Comandos sincronizados | Total: 3\n```\n\n**InteraÃ§Ãµes do usuÃ¡rio:**\n```\n2025-11-03 00:05:32 | INFO     | ğŸ”¹ Comando /ask | Servidor: 123456789 | UsuÃ¡rio: 987654321\n2025-11-03 00:05:32 | INFO     | ğŸ’¬ CMD /ask | Servidor: 123456789 | UsuÃ¡rio: 987654321 | NÃ­vel: moderado | Pergunta: Como fazer...\n2025-11-03 00:05:35 | INFO     | âœ… Resposta enviada | Servidor: 123456789 | UsuÃ¡rio: 987654321 | Fontes: 3\n```\n\n**ConfiguraÃ§Ãµes:**\n```\n2025-11-03 00:10:15 | INFO     | ğŸ”¹ Comando /config | Servidor: 123456789 | UsuÃ¡rio: 111222333 | Tentativa: liberal\n2025-11-03 00:10:15 | INFO     | ğŸ“ ConfiguraÃ§Ã£o alterada | Servidor: 123456789 | Novo nÃ­vel: liberal\n```\n\n**Erros:**\n```\n2025-11-03 00:15:20 | ERROR    | âŒ Erro ao processar | Servidor: DM | UsuÃ¡rio: 444555666 | Erro: Connection timeout\n2025-11-03 00:16:30 | WARNING  | âš ï¸ RAG nÃ£o carregado | UsuÃ¡rio: 777888999 | Servidor: None\n```\n\n### Tipos de Eventos Registrados\n- âœ… InicializaÃ§Ã£o do bot e carregamento do RAG\n- ğŸ’¬ Todas as perguntas processadas (comando, menÃ§Ã£o, DM)\n- ğŸ“ MudanÃ§as de configuraÃ§Ã£o (nÃ­vel de filtro)\n- ğŸ”¹ Uso de comandos slash (/ask, /config, /status)\n- âš ï¸ Tentativas de acesso nÃ£o autorizado\n- âŒ Erros e exceÃ§Ãµes com stack traces completos\n\n### Analisar Logs\n\n```bash\n# Ver logs em tempo real\ntail -f logs/bot.log\n\n# Buscar erros\ngrep \"ERROR\" logs/bot.log\n\n# Buscar atividade de um usuÃ¡rio especÃ­fico\ngrep \"UsuÃ¡rio: 123456789\" logs/bot.log\n\n# Ver Ãºltimas 50 linhas\ntail -n 50 logs/bot.log\n```\n\n## âš¡ OtimizaÃ§Ãµes\n\nPara reduzir custos e melhorar performance:\n\n```python\n# Reduzir nÃºmero de documentos recuperados (em bot.py)\nK_DOCS = 3  # Mudar de 5 para 3\n\n# Reduzir tokens mÃ¡ximos (em bot.py)\nmodel_kwargs={\"max_tokens\": 500}  # Mudar de 1000 para 500\n\n# Usar modelo mais barato no OpenRouter\nOPENROUTER_MODEL=anthropic/claude-3-haiku  # Mais barato que sonnet\n```\n\n## ğŸ›¡ï¸ SeguranÃ§a\n\n- âš ï¸ **Nunca** commite o arquivo `.env` (jÃ¡ estÃ¡ no `.gitignore`)\n- ğŸ”’ Mantenha seus tokens e chaves API em segredo\n- ğŸ”„ Regenere tokens se forem expostos acidentalmente\n\n## ğŸ“ PrÃ³ximos Recursos\n\n- [ ] Rate limiting para evitar spam\n- [ ] Comandos admin (recarregar banco vetorial, estatÃ­sticas)\n- [ ] Sistema de feedback com reaÃ§Ãµes (ğŸ‘/ğŸ‘)\n- [ ] Suporte a outros formatos (DOCX, TXT, Markdown)\n- [ ] Dashboard web para visualizaÃ§Ã£o de mÃ©tricas de uso\n\n## ğŸ“„ LicenÃ§a\n\nEste projeto Ã© de cÃ³digo aberto. Use livremente!\n\n## ğŸ¤ ContribuiÃ§Ãµes\n\nContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou pull requests.\n","size_bytes":7476},"load.py":{"content":"import os\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nfrom langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.vectorstores import Chroma\n\nload_dotenv()\n\nDATA_DIR = \"data\"\nINDEX_DIR = \"vectorstore\"\n\ndef load_documents():\n    \"\"\"Carrega todos os PDFs da pasta data/\"\"\"\n    print(\"[INFO] Carregando documentos...\")\n    \n    if not os.path.exists(DATA_DIR):\n        print(f\"[âŒ] DiretÃ³rio '{DATA_DIR}' nÃ£o encontrado!\")\n        print(f\"[ğŸ’¡] Crie a pasta '{DATA_DIR}' e adicione seus arquivos PDF.\")\n        return []\n    \n    pdf_files = list(Path(DATA_DIR).glob(\"*.pdf\"))\n    \n    if not pdf_files:\n        print(f\"[âŒ] Nenhum arquivo PDF encontrado em '{DATA_DIR}'\")\n        print(f\"[ğŸ’¡] Adicione arquivos .pdf na pasta '{DATA_DIR}'\")\n        return []\n    \n    print(f\"[âœ…] Encontrados {len(pdf_files)} arquivos PDF\")\n    \n    loader = DirectoryLoader(\n        DATA_DIR,\n        glob=\"**/*.pdf\",\n        loader_cls=PyPDFLoader,\n        show_progress=True\n    )\n    \n    documents = loader.load()\n    print(f\"[âœ…] {len(documents)} pÃ¡ginas carregadas\")\n    \n    return documents\n\n\ndef split_documents(documents):\n    \"\"\"Divide documentos em chunks menores\"\"\"\n    print(\"[INFO] Dividindo documentos em chunks...\")\n    \n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200,\n        length_function=len,\n        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n    )\n    \n    chunks = text_splitter.split_documents(documents)\n    print(f\"[âœ…] {len(chunks)} chunks criados\")\n    \n    return chunks\n\n\ndef create_embeddings():\n    \"\"\"Cria modelo de embeddings usando OpenAI API\"\"\"\n    print(\"[INFO] Configurando OpenAI embeddings...\")\n    \n    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n    if not openai_api_key:\n        raise ValueError(\"OPENAI_API_KEY nÃ£o encontrada no .env\")\n    \n    embeddings = OpenAIEmbeddings(\n        model=\"text-embedding-3-small\"\n    )\n    \n    print(\"[âœ…] OpenAI embeddings configurado\")\n    return embeddings\n\n\ndef create_vectorstore(chunks, embeddings):\n    \"\"\"Cria e salva Chroma vectorstore\"\"\"\n    print(\"[INFO] Criando vectorstore Chroma...\")\n    print(\"[â³] Isso pode levar alguns minutos...\")\n    \n    vectorstore = Chroma.from_documents(\n        documents=chunks,\n        embedding=embeddings,\n        persist_directory=INDEX_DIR\n    )\n    \n    print(f\"[âœ…] Vectorstore salvo em '{INDEX_DIR}'\")\n    \n    return vectorstore\n\n\ndef main():\n    \"\"\"Pipeline completo de indexaÃ§Ã£o\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸš€ INDEXAÃ‡ÃƒO DE DOCUMENTOS - RAG PT-BR\")\n    print(\"=\"*60 + \"\\n\")\n    \n    documents = load_documents()\n    \n    if not documents:\n        print(\"\\n[âŒ] Processo interrompido: nenhum documento para indexar\")\n        return\n    \n    chunks = split_documents(documents)\n    \n    if not chunks:\n        print(\"\\n[âŒ] Processo interrompido: nenhum chunk criado\")\n        return\n    \n    embeddings = create_embeddings()\n    \n    vectorstore = create_vectorstore(chunks, embeddings)\n    \n    num_vectors = len(chunks)\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"âœ… INDEXAÃ‡ÃƒO CONCLUÃDA COM SUCESSO!\")\n    print(\"=\"*60)\n    print(f\"ğŸ“Š Total de vetores: {num_vectors}\")\n    print(f\"ğŸ“ LocalizaÃ§Ã£o: {INDEX_DIR}/\")\n    print(\"\\nğŸ’¡ PrÃ³ximo passo: Execute 'python bot.py' para iniciar o bot\")\n    print(\"=\"*60 + \"\\n\")\n\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":3534}},"version":2}